{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm_Detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZaei2Rr0E4orzee9is/Py",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trongtn2110/CS114.L21/blob/master/Colab/Sarcasm_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So9wDMX6N8WH"
      },
      "source": [
        "#**CUNG CẤP CÁC THƯ VIỆN CẦN THIẾT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKyelqX7f5Pb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7rs1UVPOKSk"
      },
      "source": [
        "#**LẤY DỮ LIỆU ĐÃ THU THẬP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4hv8tc-g-Cl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex6R2wLog4Ae"
      },
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/Colab Notebooks/Data/data_sarcasm/merged_new_42.json',orient='records')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8SX6WhORDg"
      },
      "source": [
        "#**KHÁM PHÁ DỮ LIỆU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfmliwNPnItP"
      },
      "source": [
        "df.isna().sum() # Kiểm tra NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuZCEHHnMZF"
      },
      "source": [
        "sns.set_style(\"dark\")\n",
        "sns.countplot(df.is_sarcastic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyM0l1XxWtE7"
      },
      "source": [
        "#**XỬ LÝ DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRXaSNzAWzsp"
      },
      "source": [
        "##**LOẠI BỎ CÁC STOPWORDS**\n",
        "\n",
        "\n",
        "> Stopwords là những từ tiếng Anh không bổ sung nhiều ý nghĩa cho một câu. Chúng có thể được bỏ qua một cách an toàn mà không làm mất đi ý nghĩa của câu. Ví dụ, những từ như, anh ấy, có, vv Những từ như vậy đã được ghi lại điều này trong ngữ liệu có tên là ngữ liệu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGGxX4H7rxWf"
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsNPFsyRXK6q"
      },
      "source": [
        "##**XÓA CÁC KÍ TỰ KHÔNG THỂ XỬ LÝ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sreqP0ir00t"
      },
      "source": [
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Xóa các dấu ngoặc\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Xóa URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Xóa các stopwords\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "def denoise_text(text):\n",
        "    text = text.lower()\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "df['headline']=df['headline'].apply(denoise_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_1sdT_FXg0L"
      },
      "source": [
        "##**CHUYỂN ĐỔI DATA CHO PHÙ HỢP VỚI MODEL WORD2VEC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAYh8eKisS4H"
      },
      "source": [
        "words = []\n",
        "for i in df.headline.values:\n",
        "    words.append(i.split())\n",
        "words[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvCaKj24sWOl"
      },
      "source": [
        "import gensim\n",
        "EMBEDDING_DIM = 200\n",
        "#Tạo model w2v\n",
        "w2v_model = gensim.models.Word2Vec(sentences = words , size=EMBEDDING_DIM , min_count = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMGyNc5cMqs"
      },
      "source": [
        "##**MÃ HÓA DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmnKoQ5tsgAf"
      },
      "source": [
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(words)\n",
        "tokenized_train = tokenizer.texts_to_sequences(words)\n",
        "x = sequence.pad_sequences(tokenized_train, maxlen = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-tRiELnLXEo"
      },
      "source": [
        "# print(tokenizer.word_counts)\n",
        "# print(tokenizer.document_count)\n",
        "# print(tokenizer.word_index)\n",
        "# print(tokenizer.word_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBV4ilYDsigG"
      },
      "source": [
        "#Cộng 1 vì dành cho các từ không biết, vector này sẽ toàn 0\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h4-T9UDskkl"
      },
      "source": [
        "# Function to create weight matrix from word2vec gensim model\n",
        "def get_weight_matrix(model, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = model[word]\n",
        "    return weight_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-YLT7C_smVo"
      },
      "source": [
        "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXOZxXd8N7FQ"
      },
      "source": [
        "#**TRAIN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S11c78qdsoHw"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=20, trainable=True))\n",
        "#LSTM\n",
        "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.3 , dropout = 0.3,return_sequences = True)))\n",
        "model.add(Bidirectional(GRU(units=32 , recurrent_dropout = 0.1 , dropout = 0.1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "del embedding_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiuhES11sqNe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ln74B_tsr_t"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, df.is_sarcastic , test_size = 0.3 , random_state = 0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdJyK2zRst7k"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size = 128 , validation_data = (x_test,y_test) , epochs = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4BDJVg8swr0"
      },
      "source": [
        "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100)\n",
        "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(x_test,y_test)[1]*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQgbxLSfY4WO"
      },
      "source": [
        "#**NHẬN XÉT**\n",
        "- Thấy kết quả accuracy score trên Testing Data là 92.4 là khá cao so với accuracy score trên Training Data là 99.9"
      ]
    }
  ]
}